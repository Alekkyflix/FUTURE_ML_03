{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Resume Screening System\n",
        "\n",
        "This notebook implements a beginner-friendly Machine Learning system to screen and rank resumes against a job description. It includes:\n",
        "1.  Data Loading & Exploration\n",
        "2.  Text Cleaning & Preprocessing\n",
        "3.  Skill Extraction\n",
        "4.  Job Description Parsing\n",
        "5.  Similarity Scoring\n",
        "6.  Candidate Ranking\n",
        "7.  Gap Analysis & Visualization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install necessary libraries if not already installed\n",
        "!pip install pandas numpy scikit-learn nltk matplotlib seaborn spacy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import string\n",
        "import nltk\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Download NLTK data\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Data Loading"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load the dataset\n",
        "try:\n",
        "    df = pd.read_csv('resume.csv')\n",
        "    print(\"Dataset loaded successfully!\")\n",
        "    print(f\"Shape: {df.shape}\")\n",
        "    display(df.head())\n",
        "except FileNotFoundError:\n",
        "    print(\"Error: resume.csv not found. Please ensure the file exists in the current directory.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Text Cleaning & Preprocessing\n",
        "We need to clean the resume text to remove noise like URLs, special characters, and extra spaces."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def clean_text(text):\n",
        "    if not isinstance(text, str):\n",
        "        return \"\"\n",
        "    \n",
        "    text = text.lower()  # Lowercase\n",
        "    text = re.sub(r'httpS+', '', text)  # Remove URLs\n",
        "    text = re.sub(r'<.*?>', '', text)    # Remove HTML tags\n",
        "    text = re.sub(r'[^a-z0-9\\s]', '', text) # Remove special chars\n",
        "    text = re.sub(r'\\s+', ' ', text).strip() # Remove extra whitespace\n",
        "    \n",
        "    # Remove stopwords\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    words = word_tokenize(text)\n",
        "    filtered_words = [word for word in words if word not in stop_words]\n",
        "    return \" \".join(filtered_words)\n",
        "\n",
        "# Apply cleaning\n",
        "if 'Resume_str' in df.columns:\n",
        "    df['cleaned_resume'] = df['Resume_str'].apply(clean_text)\n",
        "elif 'Resume' in df.columns:\n",
        "    df['cleaned_resume'] = df['Resume'].apply(clean_text)\n",
        "else:\n",
        "    # Fallback to the first column if exact name is unknown\n",
        "    print(\"Column 'Resume_str' or 'Resume' not found. Using the first column as resume text.\")\n",
        "    df['cleaned_resume'] = df.iloc[:, 0].apply(clean_text)\n",
        "\n",
        "print(\"Preprocessing completed.\")\n",
        "display(df[['cleaned_resume']].head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Job Description Parsing\n",
        "Enter a job description to compare resumes against."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Example Job Description (You can change this)\n",
        "job_description = \"\"\"\n",
        "We are looking for a Data Scientist with experience in Python, Machine Learning, and Deep Learning.\n",
        "Key skills required: Pandas, NumPy, Scikit-Learn, TensorFlow, SQL, Data Visualization, Communication.\n",
        "Experience with Natural Language Processing (NLP) is a plus.\n",
        "\"\"\"\n",
        "\n",
        "cleaned_jd = clean_text(job_description)\n",
        "print(\"Cleaned Job Description:\")\n",
        "print(cleaned_jd)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Similarity Scoring\n",
        "We use TF-IDF to vectorize text and Cosine Similarity to score resumes against the JD."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Combine JD with Resumes for Vectorization\n",
        "all_docs = [cleaned_jd] + df['cleaned_resume'].tolist()\n",
        "\n",
        "# Vectorize\n",
        "tfidf_vectorizer = TfidfVectorizer(max_features=5000)\n",
        "tfidf_matrix = tfidf_vectorizer.fit_transform(all_docs)\n",
        "\n",
        "# Calculate Cosine Similarity\n",
        "# The first vector (index 0) is the Job Description\n",
        "cosine_sim = cosine_similarity(tfidf_matrix[0:1], tfidf_matrix[1:])\n",
        "\n",
        "# Add scores to DataFrame\n",
        "df['similarity_score'] = cosine_sim[0]\n",
        "\n",
        "# Rank candidates\n",
        "ranked_df = df.sort_values(by='similarity_score', ascending=False)\n",
        "display(ranked_df[['Category', 'similarity_score']].head(10))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Skill Extraction\n",
        "Let's identify specific skills present in the resume based on a predefined list."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define a simple skill dictionary (expand as needed)\n",
        "tech_skills = ['python', 'java', 'c++', 'sql', 'machine learning', 'deep learning', 'nlp',\n",
        "               'pandas', 'numpy', 'scikit-learn', 'tensorflow', 'keras', 'pytorch', 'tableau', 'power bi']\n",
        "\n",
        "def extract_skills(text, skill_list):\n",
        "    found_skills = []\n",
        "    for skill in skill_list:\n",
        "        if skill in text:\n",
        "            found_skills.append(skill)\n",
        "    return found_skills\n",
        "\n",
        "df['extracted_skills'] = df['cleaned_resume'].apply(lambda x: extract_skills(x, tech_skills))\n",
        "display(df[['extracted_skills']].head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Gap Analysis\n",
        "Identify which skills from the Job Description are missing in the top candidates."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "jd_skills = extract_skills(cleaned_jd, tech_skills)\n",
        "\n",
        "def find_missing_skills(resume_skills, required_skills):\n",
        "    return [skill for skill in required_skills if skill not in resume_skills]\n",
        "\n",
        "df['missing_skills'] = df['extracted_skills'].apply(lambda x: find_missing_skills(x, jd_skills))\n",
        "\n",
        "# Display Top 5 Candidates with details\n",
        "top_candidates = df.sort_values(by='similarity_score', ascending=False).head(5)\n",
        "print(f\"Required Skills: {jd_skills}\")\n",
        "display(top_candidates[['Category', 'similarity_score', 'extracted_skills', 'missing_skills']])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Visualization\n",
        "Visualize the distribution of similarity scores."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10, 6))\n",
        "sns.histplot(df['similarity_score'], bins=20, kde=True, color='skyblue')\n",
        "plt.title('Distribution of Resume Similarity Scores')\n",
        "plt.xlabel('Similarity Score')\n",
        "plt.ylabel('Count')\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
